import os
import glob
import pandas as pd
from sqlalchemy import create_engine, text
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ db_config ëª¨ë“ˆì„ importí•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from db_config import DB_CONFIG

# ---------- ì‚¬ìš©ì ì„¤ì • ----------
MYSQL_USER = DB_CONFIG['user']
MYSQL_PASSWORD = DB_CONFIG['password']
MYSQL_HOST = DB_CONFIG['host']
MYSQL_PORT = DB_CONFIG['port']
MYSQL_DATABASE = DB_CONFIG['db']
TABLE_NAME = "emergency_ex"

# íŒŒì¼ íŒ¨í„´ (ì˜ˆ: "DATA/2019_ex.xlsx", "DATA/2020_ex.xlsx", ...)
FILE_GLOB = "DATA/*_ex.xlsx"  # DATA í´ë”ì˜ ex íŒŒì¼ë“¤

# ì‹¤ì œ ì›ë³¸(ì—‘ì…€/CSV) ì»¬ëŸ¼ëª… -> MySQL í…Œì´ë¸” ì»¬ëŸ¼ëª… ë§¤í•‘
#   PTN_SYM_SE_NM - ì¦ìƒ  -> cause
#   PTN_CTPV_NM   - ì§€ì—­  -> local
#   GNDR_NM       - ì„±ë³„  -> gender
#   PTN_CR_NM     - ì§ì¥  -> job
#   PTN_CNTC_YR   - ì—°ë„  -> year
COLUMN_MAP = {
    "PTN_CNTC_YR": "year",
    "PTN_SYM_SE_NM": "cause",   # (ì‚¬ìš©ì ìš”ì²­ ê·¸ëŒ€ë¡œ 'cause' ì˜¤íƒ€ í¬í•¨)
    "GNDR_NM": "gender",
    "PTN_CTPV_NM": "local",
    "PTN_CR_NM": "job",
}

# 2022ë…„ íŒŒì¼ìš© ì»¬ëŸ¼ ì¸ë±ìŠ¤ ë§¤í•‘ (D=ì¦ìƒ, R=ì—°ë„, BM=ì§€ì—­, BP=ì§ì—…)
COLUMN_MAP_2022 = {
    17: "year",    # R - ì—°ë„
    3: "cause",    # D - ì¦ìƒ  
    62: "gender",  # ì„±ë³„
    65: "local",   # BM - ì§€ì—­ (ë™í•´ì‹œ í—¤ë”, ì‹¤ì œë¡œëŠ” ì‹œ/êµ°)
    67: "job",     # BP - ì§ì—…
}

# ì½ì„ ë•Œ ì‚¬ìš©í•  ì›ë³¸ ì»¬ëŸ¼ ìˆœì„œ(ì—†ìœ¼ë©´ ìë™ ë“œë¡­ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
SOURCE_COLS = list(COLUMN_MAP.keys())
TARGET_COLS = list(COLUMN_MAP.values())   # ë³€í™˜ í›„ MySQL í…Œì´ë¸”ì— ë“¤ì–´ê°€ëŠ” ì»¬ëŸ¼

# ---------- ì§€ì—­ëª… ë³€í™˜ í•¨ìˆ˜ ----------
def convert_region_name(region_name):
    """ì§€ì—­ëª…ì„ í’€ë„¤ì„ì—ì„œ 2ê¸€ìë¡œ ë³€í™˜"""
    if pd.isna(region_name) or region_name == '' or region_name == 'nan':
        return region_name
    
    region_name = str(region_name).strip()
    
    # ì§€ì—­ëª… ë³€í™˜ ë”•ì…”ë„ˆë¦¬
    region_mapping = {
        # ì„œìš¸íŠ¹ë³„ì‹œ -> ì„œìš¸
        'ì„œìš¸íŠ¹ë³„ì‹œ': 'ì„œìš¸',
        
        # ê´‘ì—­ì‹œë“¤
        'ë¶€ì‚°ê´‘ì—­ì‹œ': 'ë¶€ì‚°',
        'ëŒ€êµ¬ê´‘ì—­ì‹œ': 'ëŒ€êµ¬', 
        'ì¸ì²œê´‘ì—­ì‹œ': 'ì¸ì²œ',
        'ê´‘ì£¼ê´‘ì—­ì‹œ': 'ê´‘ì£¼',
        'ëŒ€ì „ê´‘ì—­ì‹œ': 'ëŒ€ì „',
        'ìš¸ì‚°ê´‘ì—­ì‹œ': 'ìš¸ì‚°',
        
        # ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ -> ì„¸ì¢…
        'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ': 'ì„¸ì¢…',
        
        # ë„ë“¤
        'ê²½ê¸°ë„': 'ê²½ê¸°',
        'ê°•ì›ë„': 'ê°•ì›',
        'ì¶©ì²­ë¶ë„': 'ì¶©ë¶',
        'ì¶©ì²­ë‚¨ë„': 'ì¶©ë‚¨',
        'ì „ë¼ë¶ë„': 'ì „ë¶',
        'ì „ë¼ë‚¨ë„': 'ì „ë‚¨',
        'ê²½ìƒë¶ë„': 'ê²½ë¶',
        'ê²½ìƒë‚¨ë„': 'ê²½ë‚¨',
        'ì œì£¼íŠ¹ë³„ìì¹˜ë„': 'ì œì£¼',
        'ì œì£¼ë„': 'ì œì£¼'
    }
    
    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
    if region_name in region_mapping:
        return region_mapping[region_name]
    
    # ë¶€ë¶„ ë§¤ì¹­ (í¬í•¨ë˜ëŠ” ê²½ìš°)
    for full_name, short_name in region_mapping.items():
        if full_name in region_name:
            return short_name
    
    # ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” ê²½ìš° ì²« 2ê¸€ì ë°˜í™˜ (ì˜ˆ: 'ì¶©ì²­ë¶ë„ì²­ì£¼ì‹œ' -> 'ì¶©ì²­')
    if len(region_name) >= 2:
        return region_name[:2]
    
    return region_name

# ---------- í•¨ìˆ˜ë“¤ ----------
def get_engine():
    url = (
        f"mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}"
        f"@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DATABASE}?charset=utf8mb4"
    )
    return create_engine(url, pool_pre_ping=True)

def ensure_table(engine):
    """
    emergency_ex í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.
    ìŠ¤í‚¤ë§ˆëŠ” ì•„ë˜ì™€ ê°™ì´ ê°€ì •í•©ë‹ˆë‹¤:
      - year: INT
      - cause, gender, local, job: VARCHAR(255)
    """
    ddl = f"""
    CREATE TABLE IF NOT EXISTS `{TABLE_NAME}` (
      `year`  INT,
      `cause` VARCHAR(255),
      `gender` VARCHAR(255),
      `local` VARCHAR(255),
      `job` VARCHAR(255)
    ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
    """
    with engine.begin() as conn:
        conn.execute(text(ddl))
        
def load_file(path: str) -> pd.DataFrame:
    """
    ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ/ì •ë¦¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    CSVë¥¼ ì‚¬ìš©í•  ê²½ìš°ì—ëŠ” pd.read_excel -> pd.read_csvë¡œ ë°”ê¾¸ì„¸ìš”.
    """
    filename = os.path.basename(path)
    
    # ì—‘ì…€: ì²« ë²ˆì§¸ ì‹œíŠ¸ ê¸°ì¤€
    df = pd.read_excel(path, dtype=str)
    
    # 2022ë…„ íŒŒì¼ì€ êµ¬ì¡°ê°€ ë‹¤ë¥´ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
    if "2022" in filename:
        print(f"ğŸ“‹ {filename}ì€ 2022ë…„ íŒŒì¼ë¡œ íŠ¹ë³„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        # 2022ë…„ íŒŒì¼ì€ ì»¬ëŸ¼ ì¸ë±ìŠ¤ë¡œ ì ‘ê·¼
        result_data = []
        for i in range(len(df)):
            row_data = {}
            for col_idx, target_col in COLUMN_MAP_2022.items():
                if col_idx < len(df.columns):
                    row_data[target_col] = str(df.iloc[i, col_idx]).strip() if pd.notna(df.iloc[i, col_idx]) else ""
                else:
                    row_data[target_col] = ""
            result_data.append(row_data)
        
        result_df = pd.DataFrame(result_data)
        
    else:
        # ê¸°ì¡´ íŒŒì¼ë“¤ ì²˜ë¦¬ (2019-2021, 2023 ë“±)
        # í•„ìš”í•œ ì›ë³¸ ì»¬ëŸ¼ ì²´í¬
        missing = [c for c in SOURCE_COLS if c not in df.columns]
        if missing:
            raise ValueError(f"{filename}ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")

        # í•„ìš”í•œ ì›ë³¸ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        df = df[SOURCE_COLS].copy()

        # ì»¬ëŸ¼ëª… ë§¤í•‘ -> íƒ€ê²Ÿ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½
        result_df = df.rename(columns=COLUMN_MAP)

    # ë¬¸ìì—´ ê³µë°± ì œê±°
    for col in result_df.columns:
        if result_df[col].dtype == object:
            result_df[col] = result_df[col].astype(str).str.strip()

    # ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ ì¹˜í™˜ ("" -> <NA>)
    result_df = result_df.replace({"": pd.NA})

    # ì§€ì—­ëª… ë³€í™˜ (í’€ë„¤ì„ -> 2ê¸€ì)
    if 'local' in result_df.columns:
        result_df['local'] = result_df['local'].apply(convert_region_name)
        print(f"'{filename}'ì—ì„œ ì§€ì—­ëª…ì„ 2ê¸€ìë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.")

    # year ìˆ«ì ë³€í™˜ (ì‹¤íŒ¨ ì‹œ NaNìœ¼ë¡œ)
    result_df["year"] = pd.to_numeric(result_df["year"], errors="coerce").astype("Int64")

    # ìµœì¢… ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
    missing_target = [c for c in TARGET_COLS if c not in result_df.columns]
    if missing_target:
        raise ValueError(
            f"ë§¤í•‘ í›„ ëˆ„ë½ëœ íƒ€ê²Ÿ ì»¬ëŸ¼: {missing_target}. COLUMN_MAP/TARGET_COLS ì„¤ì • í™•ì¸ í•„ìš”."
        )

    # íƒ€ê²Ÿ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê³  ìˆœì„œ ê³ ì •
    result_df = result_df[TARGET_COLS]

    # âœ… íƒ€ê²Ÿ ì»¬ëŸ¼ ì¤‘ í•˜ë‚˜ë¼ë„ ë¹„ì–´ ìˆìœ¼ë©´ í–‰ ì œê±°
    result_df = result_df.dropna(subset=TARGET_COLS, how="any")

    # âœ… ì§€ì—­ì´ 'ì „ì²´'ì¸ ê²½ìš° ì œì™¸
    if 'local' in result_df.columns:
        before_count = len(result_df)
        result_df = result_df[result_df['local'] != 'ì „ì²´']
        after_count = len(result_df)
        removed_count = before_count - after_count
        if removed_count > 0:
            print(f"'{filename}'ì—ì„œ ì§€ì—­ì´ 'ì „ì²´'ì¸ {removed_count}ê°œ í–‰ì„ ì œì™¸í–ˆìŠµë‹ˆë‹¤.")

    # (ì„ íƒ) NaN -> None (to_sqlì—ì„œ NULLë¡œ ì¸ì‹ë˜ê²Œ í•˜ê³  ì‹¶ë‹¤ë©´ ìœ ì§€)
    result_df = result_df.where(pd.notnull(result_df), None)

    return result_df

def main():
    engine = get_engine() # db ì—°ê²° ì—”ì§„ ìƒì„±
    ensure_table(engine) # í…Œì´ë¸” ì¡´ì¬ í™•ì¸/ìƒì„±

    files = sorted(glob.glob(FILE_GLOB))
    if not files:
        print(f"íŒ¨í„´ '{FILE_GLOB}'ì— ë§ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    print(f"ë°œê²¬ëœ íŒŒì¼: {files}")

    total_rows = 0
    for fp in files:
        print(f"ì²˜ë¦¬ ì¤‘: {fp}")
        df = load_file(fp)

        # ë¯¸ë¦¬ë³´ê¸°(ì„ íƒ) â€” ë¬¸ì œ ì—†ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬í•´ë„ ë©ë‹ˆë‹¤.
        print(df.head(3))

        # MySQLì— ì ì¬ (append)
        df.to_sql(
            name=TABLE_NAME,
            con=engine,
            if_exists="append",
            index=False,
            method="multi",
            chunksize=1000,
        )
        total_rows += len(df)

    print(f"ì ì¬ ì™„ë£Œ: ì´ {total_rows}í–‰ì„ '{TABLE_NAME}' í…Œì´ë¸”ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
